{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = '/barleyhome/sgutstei/101_ObjectCategories_32x32'\n",
    "dir2 = '/barleyhome/sgutstei/101_ObjectCategories_32x32_b'\n",
    "os.makedirs(os.path.join(dir1,'cifar_style_datasets'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dir2,'cifar_style_datasets'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = sorted([x for x in os.listdir(dir1) if len(os.listdir(os.path.join(dir1,x)))>0])\n",
    "categories_dict = {x:ctr for ctr,x in enumerate(categories)}\n",
    "inv_categories_dict = {v: k for k, v in categories_dict.items()}\n",
    "#inv_categories_dict\n",
    "#pickle.dump(inv_categories_dict,open('caltech101_dicts_all.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_elems(im_root, ims, category, fine_label):\n",
    "\n",
    "    cl_list = []\n",
    "    fl_list = []\n",
    "    fn_list = []\n",
    "    im_list = []\n",
    "\n",
    "    for curr_im in ims:\n",
    "        with Image.open(os.path.join(im_root, category, curr_im)) as z:\n",
    "            z=z.convert('RGB')\n",
    "            z=z.resize((32,32),Image.ANTIALIAS)\n",
    "            zz=np.asarray(z)\n",
    "            zz=zz.transpose(2,0,1)\n",
    "            zz=zz.reshape(1,3*32*32)\n",
    "        \n",
    "        coarse_label=fine_label\n",
    "        cl_list.append(coarse_label)\n",
    "        fl_list.append(fine_label)\n",
    "        fn_list.append(\"_\".join([category,curr_im]))\n",
    "        im_list.append(zz)\n",
    "\n",
    "    if len(im_list) < 1:\n",
    "        import pdb\n",
    "        pdb.set_trace()\n",
    "        temp=0\n",
    "    im_array = np.concatenate(im_list)\n",
    "    return [cl_list, fl_list, fn_list,  im_array]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(src_dir):\n",
    "    #categories = sorted([x for x in os.listdir(dir1) if len(os.listdir(os.path.join(dir1,x)))>0])\n",
    "    #categories_dict = {x:ctr for ctr,x in enumerate(categories)}\n",
    "    #inv_categories_dict = {v: k for k, v in categories_dict.items()}\n",
    "\n",
    "    train_cl_list = []\n",
    "    train_fl_list = []\n",
    "    train_fn_list = []\n",
    "    train_im_list = []\n",
    "\n",
    "    test_cl_list = []\n",
    "    test_fl_list = []\n",
    "    test_fn_list = []\n",
    "    test_im_list = []\n",
    "\n",
    "    for curr_cat in categories:\n",
    "        all_ims = [x for x in os.listdir(os.path.join(dir1,curr_cat)) if x[-4:] == '.jpg']\n",
    "        num_ims = len(all_ims)\n",
    "        random.shuffle(all_ims)\n",
    "        tr_ims = all_ims[0:int(.83*num_ims)]\n",
    "        te_ims = all_ims[int(.83*num_ims):]\n",
    "\n",
    "        new_tr_info = get_data_elems(dir1, tr_ims, curr_cat, \n",
    "                                     categories_dict[curr_cat])\n",
    "\n",
    "        train_cl_list += new_tr_info[0]\n",
    "        train_fl_list += new_tr_info[1]\n",
    "        train_fn_list += new_tr_info[2]\n",
    "        train_im_list.append(new_tr_info[3])\n",
    "\n",
    "        new_te_info = get_data_elems(dir1, te_ims, curr_cat, \n",
    "                                     categories_dict[curr_cat])\n",
    "\n",
    "        test_cl_list += new_te_info[0]\n",
    "        test_fl_list += new_te_info[1]\n",
    "        test_fn_list += new_te_info[2]\n",
    "        test_im_list.append(new_te_info[3])\n",
    "\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    train_im_array = np.concatenate(train_im_list)\n",
    "    test_im_array = np.concatenate(test_im_list)\n",
    "    \n",
    "    return [[train_cl_list, train_fl_list, train_fn_list, train_im_array],\n",
    "            [test_cl_list, test_fl_list, test_fn_list, test_im_array]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dataset(cl_list, fl_list, fn_list, im_array):\n",
    "\n",
    "    shuff_array = np.zeros(im_array.shape, dtype=im_array.dtype)\n",
    "    num_images = im_array.shape[0]\n",
    "    shuff_list = [x for x in range(num_images)]\n",
    "    random.shuffle(shuff_list)\n",
    "\n",
    "    shuff_cl = num_images * [None]\n",
    "    shuff_fl = num_images * [None]\n",
    "    shuff_fn = num_images * [None]\n",
    "\n",
    "    for new, old in enumerate(shuff_list):\n",
    "        print(\"Shuffling \",new,\"of\",len(shuff_list))\n",
    "        shuff_cl[new] = cl_list[old]\n",
    "        shuff_fl[new] = fl_list[old]\n",
    "        shuff_fn[new] = fn_list[old]\n",
    "        shuff_array[new,:] = im_array[old,:]\n",
    "\n",
    "    return [shuff_cl, shuff_fl, shuff_fn, shuff_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-8-f935c7177a41>\u001b[0m(41)\u001b[0;36mmake_datasets\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     39 \u001b[0;31m    \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     40 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 41 \u001b[0;31m    \u001b[0mtrain_im_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_im_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     42 \u001b[0;31m    \u001b[0mtest_im_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_im_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     43 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> len(train_im_list)\n",
      "0\n",
      "ipdb> categories\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "tr1, te1 = make_datasets(dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shtr1 = shuffle_dataset(tr1[0], tr1[1], tr1[2], tr1[3])\n",
    "shte1 = shuffle_dataset(te1[0], te1[1], te1[2], te1[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(samp, data_dict):\n",
    "    test_im = data_dict[3][samp]\n",
    "    zz=test_im.reshape(1,3,32,32)\n",
    "    zz=zz[0,:]\n",
    "    zz=zz.transpose(1,2,0)\n",
    "    im_name = inv_categories_dict[data_dict[1][samp]]\n",
    "    file_name = data_dict[2][samp]\n",
    "    print(im_name, file_name)\n",
    "    imshow(zz)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(5500, shtr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shtr_dict = {'coarse_labels': shtr1[0], 'fine_labels':shtr1[1], \n",
    "             'filenames':shtr1[2],'data':shtr1[3], 'batch_label':\"N/A\"}\n",
    "shte_dict = {'coarse_labels': shte1[0], 'fine_labels':shte1[1], \n",
    "             'filenames':shte1[2],'data':shte1[3], 'batch_label':\"N/A\"}\n",
    "\n",
    "meta_list = [inv_categories_dict[x] for x in inv_categories_dict]\n",
    "meta_dict = {'coarse_label_names':meta_list, 'fine_label_names':meta_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(shtr_dict,open(\"train\",\"wb\"))\n",
    "pickle.dump(shte_dict,open(\"test\",\"wb\"))\n",
    "pickle.dump(meta_dict,open(\"meta\",\"wb\"))\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(categories_dict, \n",
    "            open('/home/smgutstein/Projects/opt-tfer-2/dataset_info/caltech101_dicts_all.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv=['sunflower', 'scorpion', 'dolphin', 'stegosaurus', 'hawksbill',\n",
    "        'water_lilly', 'dragonfly', 'crayfish', 'Leopards', 'cannon',\n",
    "        'flamingo_head', 'tick', 'Faces', 'cougar_body', 'flamingo',\n",
    "        'crocodile', 'bonsai', 'gerenuk', 'emu', 'panda', 'ant',\n",
    "        'butterfly', 'ibis', 'hedgehog', 'pigeon', 'beaver',\n",
    "        'platypus', 'lotus', 'wild_cat', 'crab', 'strawberry',\n",
    "        'rooster', 'sea_horse', 'llama', 'trilobite', 'brontosaurus',\n",
    "        'nautilus', 'rhino', 'mayfly', 'airplanes', 'lobster',\n",
    "        'okapi', 'dalmatian', 'crocodile_head', 'bass', 'joshua_tree',\n",
    "        'kangaroo', 'cougar_face', 'octopus', 'elephant', 'starfish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl=['Motorbikes', 'accordion', 'anchor', 'barrel', 'binocular',\n",
    "        'brain', 'buddha', 'camera', 'car_side', 'ceiling_fan',\n",
    "        'cellphone', 'chair', 'chandelier', 'cup', 'dollar_bill',\n",
    "        'electric_guitar', 'euphonium', 'ewer', 'ferry', 'garfield',\n",
    "        'gramophone', 'grand_piano', 'headphone', 'helicopter', 'inline_skate',\n",
    "        'ketch', 'lamp', 'laptop', 'mandolin', 'menorah', \n",
    "        'metronome', 'minaret', 'pagoda', 'pizza', 'pyramid',\n",
    "        'revolver', 'saxophone', 'schooner', 'scissors', 'snoopy',\n",
    "        'soccer_ball', 'stapler', 'stop_sign', 'umbrella', 'watch',\n",
    "        'wheelchair', 'windsor_chair', 'wrench', 'yin_yang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subset_datasets(src_dir, categories):\n",
    "    #categories_dict = {x:ctr for ctr,x in enumerate(categories)}\n",
    "    #inv_categories_dict = {v: k for k, v in categories_dict.items()}\n",
    "\n",
    "    train_cl_list = []\n",
    "    train_fl_list = []\n",
    "    train_fn_list = []\n",
    "    train_im_list = []\n",
    "\n",
    "    test_cl_list = []\n",
    "    test_fl_list = []\n",
    "    test_fn_list = []\n",
    "    test_im_list = []\n",
    "\n",
    "    for curr_cat in categories:\n",
    "        all_ims = [x for x in os.listdir(os.path.join(dir1,curr_cat)) if x[-4:] == '.jpg']\n",
    "        num_ims = len(all_ims)\n",
    "        random.shuffle(all_ims)\n",
    "        #print(curr_cat,num_ims)\n",
    "        tr_ims = all_ims[0:int(.83*num_ims)]\n",
    "        te_ims = all_ims[int(.83*num_ims):]\n",
    "\n",
    "        new_tr_info = get_data_elems(dir1, tr_ims, curr_cat, \n",
    "                                     categories_dict[curr_cat])\n",
    "\n",
    "        train_cl_list += new_tr_info[0]\n",
    "        train_fl_list += new_tr_info[1]\n",
    "        train_fn_list += new_tr_info[2]\n",
    "        train_im_list.append(new_tr_info[3])\n",
    "\n",
    "        new_te_info = get_data_elems(dir1, te_ims, curr_cat, \n",
    "                                     categories_dict[curr_cat])\n",
    "\n",
    "        test_cl_list += new_te_info[0]\n",
    "        test_fl_list += new_te_info[1]\n",
    "        test_fn_list += new_te_info[2]\n",
    "        test_im_list.append(new_te_info[3])\n",
    "\n",
    "    train_im_array = np.concatenate(train_im_list)\n",
    "    test_im_array = np.concatenate(test_im_list)\n",
    "    \n",
    "    return [[train_cl_list, train_fl_list, train_fn_list, train_im_array],\n",
    "            [test_cl_list, test_fl_list, test_fn_list, test_im_array]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_tr, liv_te = make_subset_datasets(dir1,liv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_shtr = shuffle_dataset(liv_tr[0], liv_tr[1], liv_tr[2], liv_tr[3])\n",
    "liv_shte = shuffle_dataset(liv_te[0], liv_te[1], liv_te[2], liv_te[3])\n",
    "\n",
    "liv_shtr_dict = {'coarse_labels': liv_shtr[0], 'fine_labels':liv_shtr[1], \n",
    "             'filenames':liv_shtr[2],'data':liv_shtr[3], \n",
    "             'batch_label':\"N/A\"}\n",
    "liv_shte_dict = {'coarse_labels': liv_shte[0], 'fine_labels':liv_shte[1], \n",
    "             'filenames':liv_shte[2],'data':liv_shte[3], \n",
    "             'batch_label':\"N/A\"}\n",
    "meta_dict = {'coarse_label_names':liv, 'fine_label_names':liv}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(liv_shte_dict['fine_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nliv_tr, nliv_te = make_subset_datasets(dir1,nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nliv_shtr = shuffle_dataset(nliv_tr[0], nliv_tr[1], nliv_tr[2], nliv_tr[3])\n",
    "nliv_shte = shuffle_dataset(nliv_te[0], nliv_te[1], nliv_te[2], nliv_te[3])\n",
    "meta_dict = {'coarse_label_names':nl, 'fine_label_names':nl}\n",
    "\n",
    "nliv_shtr_dict = {'coarse_labels': nliv_shtr[0], 'fine_labels':nliv_shtr[1], \n",
    "             'filenames':nliv_shtr[2],'data':nliv_shtr[3], \n",
    "             'batch_label':\"N/A\"}\n",
    "nliv_shte_dict = {'coarse_labels': nliv_shte[0], 'fine_labels':nliv_shte[1], \n",
    "             'filenames':nliv_shte[2],'data':nliv_shte[3], \n",
    "             'batch_label':\"N/A\"}\n",
    "meta_dict = {'coarse_label_names':nl, 'fine_label_names':nl}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(liv_shtr_dict,open(\"train_src\",\"wb\"))\n",
    "pickle.dump(liv_shte_dict,open(\"test_src\",\"wb\"))\n",
    "pickle.dump(meta_dict,open(\"meta_src\",\"wb\"))\n",
    "\n",
    "pickle.dump(nliv_shtr_dict,open(\"train_trgt\",\"wb\"))\n",
    "pickle.dump(nliv_shte_dict,open(\"test_trgt\",\"wb\"))\n",
    "pickle.dump(meta_dict,open(\"meta_trgt\",\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
